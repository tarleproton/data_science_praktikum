Клиенту нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Задачей было - обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок. 
В проекте был использован BERT.
Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.
