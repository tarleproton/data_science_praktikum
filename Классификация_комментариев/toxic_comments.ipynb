{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План \n",
    "\n",
    "Выполнить токенизацию каждого текста, то есть его разбивают на слова;\n",
    "\n",
    "Лемматизировать слова: привести к начальной словарной форме (BERT, этого не требуют: они сами понимают формы слов);\n",
    "\n",
    "Текст очищают от стоп-слов и ненужных символов;\n",
    "\n",
    "Для корректной работы алгоритма добавить маркеры начала и конца предложения.\n",
    "\n",
    "На выходе у каждого исходного текста образуется свой список токенов.\n",
    "\n",
    "Затем токены передают модели, которая переводит их в векторные представления. Для этого модель обращается к составленному заранее словарю токенов. На выходе для каждого текста образуются векторы заданной длины.\n",
    "\n",
    "На финальном этапе модели передают признаки (векторы). И она прогнозирует эмоциональную окраску текста — 0 («отрицательная») или 1 («положительная»)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy  as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "comments.info()\n",
    "#нет пропусков , с форматом все в порядке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['text'].duplicated().sum()\n",
    "#полных дубликатов - нет. а вдруг)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments['toxic'].hist()\n",
    "comments['toxic'].value_counts()\n",
    "#есть явный дисбаланс\n",
    "#в дальнейшем с ним нужно бороться\n",
    "#забегая вперед - апсемплинг, даунсемплинг положительных результатов не показывали\n",
    "#настраивал веса классов в моделях вручную, автоматический баланс - показывал результаты хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процентное соотношение классов: 0.10167887648758234\n"
     ]
    }
   ],
   "source": [
    "print('Процентное соотношение классов:',comments['toxic'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.74 s, sys: 76.9 ms, total: 2.82 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 2.95 s\n",
    "#очиcтим текст от ненужных символов\n",
    "def clear_text(text):\n",
    "    subs = re.sub(r'[^a-zA-Z ^0-9]', ' ', text)\n",
    "    clear_txt =  ' '.join(subs.split())\n",
    "    return clear_txt\n",
    "\n",
    "comments['clear'] = comments['text'].apply(\n",
    "  lambda x: clear_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Займемся преобразованием текста , будем использовать NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 692 ms, total: 1min 8s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 2min 18s\n",
    "#разобъем на слова\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "def token(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "comments['token'] = comments['clear'].apply(\n",
    "  lambda x: token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.5 s, sys: 567 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 1min 10s\n",
    "#лемматизируем\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma(text):\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in text])\n",
    "    return  lemmatized_output     \n",
    "\n",
    "comments['lemma'] = comments['token'].apply(\n",
    "  lambda x: lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 s, sys: 87.8 ms, total: 13.3 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 13.1 s\n",
    "#уберм стоп слова\n",
    "#не указывал список стоп-слов при создании TfidfVectorizer, метрика падала\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "def clear_stopwords(text): \n",
    "        \n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
    "    text_clear = pattern.sub('', text)\n",
    "    return text_clear\n",
    "\n",
    "comments['final_text'] = comments['lemma'].apply(\n",
    "      lambda x: clear_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>[Explanation, Why, the, edits, made, under, my...</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>Explanation Why edits made username Hardcore M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>[D, aww, He, matches, this, background, colour...</td>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "      <td>D aww He match background colour I seemingly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>[Hey, man, I, m, really, not, trying, to, edit...</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>Hey man I really trying edit war It guy consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "      <td>[More, I, can, t, make, any, real, suggestions...</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "      <td>More I make real suggestion improvement I wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[You, sir, are, my, hero, Any, chance, you, re...</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>You sir hero Any chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                               clear  \\\n",
       "0  Explanation Why the edits made under my userna...   \n",
       "1  D aww He matches this background colour I m se...   \n",
       "2  Hey man I m really not trying to edit war It s...   \n",
       "3  More I can t make any real suggestions on impr...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [Explanation, Why, the, edits, made, under, my...   \n",
       "1  [D, aww, He, matches, this, background, colour...   \n",
       "2  [Hey, man, I, m, really, not, trying, to, edit...   \n",
       "3  [More, I, can, t, make, any, real, suggestions...   \n",
       "4  [You, sir, are, my, hero, Any, chance, you, re...   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  Explanation Why the edits made under my userna...   \n",
       "1  D aww He match this background colour I m seem...   \n",
       "2  Hey man I m really not trying to edit war It s...   \n",
       "3  More I can t make any real suggestion on impro...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                          final_text  \n",
       "0  Explanation Why edits made username Hardcore M...  \n",
       "1  D aww He match background colour I seemingly s...  \n",
       "2  Hey man I really trying edit war It guy consta...  \n",
       "3  More I make real suggestion improvement I wond...  \n",
       "4             You sir hero Any chance remember page   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()\n",
    "#получили финальную таблицу с преобработанным текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#эти данные мы будем применять для векторизации без N-грамм\n",
    "target = comments['toxic']\n",
    "features = comments['final_text']\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target,  test_size=0.20, random_state=8888)\n",
    "#Для задач NLP важен объём именно обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процентное соотношение классов в учебной выборке: 0.10205552422134487\n"
     ]
    }
   ],
   "source": [
    "print('Процентное соотношение классов в учебной выборке:',target_train.mean())\n",
    "#почти не изменилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процентное соотношение классов в тестовой выборке: 0.1001723327588908\n"
     ]
    }
   ],
   "source": [
    "print('Процентное соотношение классов в тестовой выборке:',target_test.mean())\n",
    "#почти не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что чтобы применить N-граммы, необходимо оставить все слова на месте и производить векторизацию, не убирая стоп слова.\n",
    "Эти данные оставил для векторизации с применением N-грамм\n",
    "\n",
    "target = comments['toxic']\n",
    "features = comments['clear']\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target,  test_size=0.30, random_state=8888)\n",
    "\n",
    "при применении N-грамм результаты на LogisticRegression после cv были чуть хуже, чем без пременения таковых\n",
    "а именно 0.7606624057281104  по целевой метрике. Поскольку других кретериев оценки в данном проекте мы не \n",
    "рассматривали, я решил отказаться от применения N-грамм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим векторизацию с помощью tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#векторизация\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)  #ngram_range=(1, 2)\n",
    "features_train = count_tf_idf.fit_transform(features_train)\n",
    "features_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 s, sys: 5.11 s, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 4.3}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=888, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 13.6 s\n",
    "model_LogReg = LogisticRegression(random_state=888, class_weight={0:1,1:4.3})\n",
    "\n",
    "model_LogReg.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cros_val(model,features_t,target_t):\n",
    "\n",
    "    score_f1 = statistics.mean(cross_val_score(model, features_t,\\\n",
    "                                                        target_t, cv=5, scoring='f1'))\n",
    "    print('Метрика F1 для модели', model,':',score_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 для модели LogisticRegression(C=1.0, class_weight={0: 1, 1: 4.3}, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=888, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) : 0.7767357542079225\n",
      "CPU times: user 29.9 s, sys: 19 s, total: 48.9 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 46.6 s\n",
    "cros_val(model_LogReg, features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "1h 22m 28s\n",
    "model_CatC = CatBoostClassifier(random_state=888,\n",
    "                           verbose=100, class_weights=[1, 4.5], iterations = 1000)\n",
    "\n",
    "\n",
    "model_CatC.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 для константной модели : 0.0\n",
      "Метрика accuracy_score для константной модели : 0.8979444757786551\n"
     ]
    }
   ],
   "source": [
    "#проверка на константной модели\n",
    "predicted_model_const = pd.Series(target_train.min(), index=target_train.index)\n",
    "print(\"Метрика F1 для константной модели :\", f1_score(target_train, predicted_model_const))\n",
    "print(\"Метрика accuracy_score для константной модели :\",accuracy_score(target_train, predicted_model_const))\n",
    "# Показатель F1 меры равен 0 по причине вывода константной модели лишь отрицательных ответов.\n",
    "#accuracy_score равен 0,89, здорово)! Но вспомним про дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу - LogisticRegression дает приемлемый результат при ручной подборке весов, то же касается и Catboost.\n",
    "Проводить grid_search - в CatBoost с cv не стал, это занимало феноменально много времени(Сделал grid_search когда обрабатывал данных с помощью bert в colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим обработку текста с помощью BERT.\n",
    "\n",
    "Весь код закомменчен , по причине выполнения его мной в Google Colaboratory с преминением GPU. При желании его можно воспроизвести в colabe).\n",
    "Плюс BERT обучался на последовательностях длины не больше 512 токенов, но, как я понимаю, этого с избытком хватает для нашей задачи. И, посмотрев распределение длинн токенов, можно прийти к выводу, что большинство их входит в 400. Именно ей я и ограничился. Все это ускорило получение эмбиндингов.\n",
    "Результаты модели CatBoostClassifier по метрике f1 на тестовой выборке: 0.6934299954689623\n",
    "Результаты модели LogisticRegression по метрике f1 на тестовой выборке: 0.705975256646486\n",
    "Выдающимися их не назовешь...\n",
    "Возможно стоило ещё поработать на моделями.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy  as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "!pip install catboost\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Загрузка предобученной модели/токенизатора \n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "  model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#2min 48s\n",
    "#Wall time: Wall time: 3min 8s\n",
    "tokenized = comments['text'].apply((lambda x: tokenizer.encode(x, max_length=400, truncation=True, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#максимальная длинна нам уже известна, мы установили её на 400\n",
    "max_len = 400\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import notebook\n",
    "batch_size = 16\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "        \n",
    "#10638/10638 [1:18:16<00:00, 2.27it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bert = comments['toxic']\n",
    "features_bert = np.concatenate(embeddings)\n",
    "features_train_bert, features_test_bert, target_train_bert, target_test_bert = train_test_split(\n",
    "    features_bert, target_bert, test_size=0.30, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LogReg_bert = LogisticRegression(random_state=888, class_weight={0 : 1, 1 : 1.4} )\n",
    "\n",
    "model_LogReg_bert.fit(features_train_bert, target_train_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cros_val(model,features_t,target_t):\n",
    "\n",
    "    score_f1 = statistics.mean(cross_val_score(model, features_t,\\\n",
    "                                                        target_t, cv=5, scoring='f1'))\n",
    "    print('Метрика F1 для модели', model,':',score_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cros_val(model_LogReg_bert, features_train_bert, target_train_bert)\n",
    "#Метрика F1 для модели LogisticRegression(C=1.0, class_weight={0: 1, 1: 4.3}, dual=False,\n",
    "                   #fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   #max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   #random_state=888, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   #warm_start=False) : 0.7035912049841136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, cv\n",
    "model_Cat_bert = CatBoostClassifier()\n",
    "\n",
    "\n",
    "cv_dataset = Pool(data=features_train_bert,\n",
    "                  label=target_train_bert)\n",
    "\n",
    "grid = {'learning_rate': [0.03 ,0.3, 0.6],\n",
    "        'depth': [3,4,6],\n",
    "        'class_weights':[[1, 4.5],[1, 1.5]]}\n",
    "\n",
    "grid_search_result = model_Cat_bert.grid_search(grid, \n",
    "                                       X=cv_dataset,\n",
    "                                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_result\"\n",
    "# 'params': {'class_weights': [1.0, 4.5], 'depth': 6, 'learning_rate': 0.03}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log_bert = model_LogReg_bert.predict(features_test_bert)\n",
    "predict_cat_bert = model_Cat_bert.predict(features_test_bert)\n",
    "f1_log = f1_score(target_test_bert, predict_log_bert)\n",
    "f1_cat = f1_score(target_test_bert, predict_cat_bert)\n",
    "print(\"Результаты модели CatBoostClassifier по метрике f1:\", f1_cat)\n",
    "print(\"Результаты модели LogisticRegression по метрике f1:\", f1_log)\n",
    "\n",
    "#Результаты модели CatBoostClassifier по метрике f1: 0.6934299954689623\n",
    "#Результаты модели LogisticRegression по метрике f1: 0.705975256646486"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузим модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_LogReg_bert, 'model.model_LogReg_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_Cat_bert, 'model.model_Cat_bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1001723327588908"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим распределение на тестовой выборке\n",
    "target_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log = model_LogReg.predict(features_test)\n",
    "#predict_cat = model_CatC.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(target, answer):\n",
    "    print(\"F1:\", f1_score(target, answer))\n",
    "    print('====================================================')\n",
    "    from sklearn import metrics\n",
    "    print(metrics.classification_report(target, answer))\n",
    "    tn, fn, fp, tp = confusion_matrix(target, answer).ravel()\n",
    "    print('True Negdtive:', tn)\n",
    "    print('False Negative:', fn)\n",
    "    print('True Positive:', tp)\n",
    "    print('False Positive:', fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.769159599074788\n",
      "====================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     28718\n",
      "           1       0.76      0.78      0.77      3197\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.87      0.88      0.87     31915\n",
      "weighted avg       0.95      0.95      0.95     31915\n",
      "\n",
      "True Negdtive: 27924\n",
      "False Negative: 794\n",
      "True Positive: 2494\n",
      "False Positive: 703\n"
     ]
    }
   ],
   "source": [
    "metrics(target_test, predict_log)\n",
    "#F1: 0.773615635179153\n",
    "#F1: 0.7732115677321157\n",
    "#F1: 0.7693247784906813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(target_test, predict_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_new = pd.DataFrame({'0':model_LogReg.predict_proba(features_test)[:,0], '1':model_LogReg.predict_proba(features_test)[:,1], \\n                      'tru': target_test, 'pred': predict_log})\\n\\ndf_new['pred'] = df_new['1']  > 0.33\\ndf_new['pred'] = (df_new['pred'])*1\\ntn, fn, fp, tp = confusion_matrix(target_test, df_new['pred']).ravel()\\nprint(tn, fn, fp, tp)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#можно было побаловаться с порогами, но отложил это.\n",
    "'''df_new = pd.DataFrame({'0':model_LogReg.predict_proba(features_test)[:,0], '1':model_LogReg.predict_proba(features_test)[:,1], \n",
    "                      'tru': target_test, 'pred': predict_log})\n",
    "\n",
    "df_new['pred'] = df_new['1']  > 0.33\n",
    "df_new['pred'] = (df_new['pred'])*1\n",
    "tn, fn, fp, tp = confusion_matrix(target_test, df_new['pred']).ravel()\n",
    "print(tn, fn, fp, tp)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашей задачей было разработать модель для определения токсичных комментариев и дальнейшей отправки их на модерацию.\n",
    "Я провёл два варианта обработки текста :\n",
    "С помощью инструментов nltk и дальнейшей векторизации через TfidfVectorizer.\n",
    "С помощью инструментов bert\n",
    "В дальнейшем в обоих вариантах подготовленные данные загружались в две модели - LogisticRegression и CatBoostClassifier.\n",
    "Результат на целевой метрике сцепок tf_idf / LogisticRegression и tf_idf / CatBoostClassifier почти одинаковы, LogisticRegression естественно шустрее и в процессе  обучения.\n",
    "Результаты с применением bert были на порядок хуже(явно из за моего невежества)\n",
    "Если рассматривать полезность нашей роботы, то стоило бы смотреть на такие показатели, как полнота и точность. И обговаривать с заказчиком , что для него важнее: пропустить токсичный комментарий или загрузить модератора лишней работой.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
