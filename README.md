# toxic_comments
Клиенту нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Задачей было - обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок и получить значение целевой метрики *F1* не меньше 0.75. И попробовать для выполнения проекта применять BERT.

К сожалению не могу выложить датасет , он находился не в открытом доступе. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.
